---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
rm(list=ls())
```

```{r}
data <- read.csv('data.csv', header=TRUE);
data <- data.frame(data);
print(data);
```

We need to remove NA cells using na.omit(). Then, we turn 1 and 2 values diagnosis into 0 and 3-value into 1.

```{r}
Dfprediction = na.omit(data)
Dfprediction$diagnosis= 1*(Dfprediction$diagnosis == 3)
print(Dfprediction)
```

We split the dataset in two parts. Taking 80% of patients, we build a training dataset on which we will fit the parameters of our logistic model. On the remaining 20% of patients, we will evaluate the performance of our model.

```{r}
#Starting code
#Creating the training and test sets
sample_size <- floor(0.8 * nrow(Dfprediction))
train_ind <- sample(nrow(Dfprediction), size = sample_size)
Dfprediction.train <- as.data.frame(Dfprediction[train_ind,])
Dfprediction.test <- as.data.frame(Dfprediction[-train_ind,])
#Logistic regression
Dfprediction.function = paste("diagnosis", "~", "REG1B + TFF1 + REG1A")
Dfprediction.glm = glm(as.formula(Dfprediction.function), data = Dfprediction.train , family = binomial)
summary(Dfprediction.glm)
```

# II) Likelihood ratio test This test aims to evaluate the dependency on parameters, ie to evaluate the correlation between the presence of the biomarkers and the presence of cancer.

```{r}
#lrtest= the generic function to carry out a likelihood ratio test. 
## Definition of the null and alternative hypoteses
pvalue_LRtest<- function(var){
null_hyp <- glm(diagnosis ~ 1, data=Dfprediction);
alternative_hyp <- glm(paste("diagnosis", "~", as.character(var)),data=Dfprediction);
res_lrtest <- lrtest(null_hyp, alternative_hyp);
res_lrtest$`Pr(>Chisq)`[2]; 
}
print(colnames(Dfprediction))
names <- colnames(Dfprediction);
names <- names[names != 'diagnosis'];
pvalues <- sapply(names, pvalue_LRtest);
# sapply: to apply a function to each element of a vector 
names(pvalues)<- names_parameters;
pvalues[order(pvalues, decreasing=FALSE)];
```

```{r}
library(lmtest)
pvalue_LRTest <- function(var){
  globalnull <- glm(diagnosis  ~ 1, data=Dfprediction);
  alternative <- glm(paste("diagnosis", "~", as.character(var)),data=Dfprediction);
  res_lrtest <- lrtest(globalnull, alternative);
  res_lrtest$`Pr(>Chisq)`[2];
}
names_features <- colnames(Dfprediction);
names_features <- names_features[names_features != 'diagnosis'];
pvalues <- sapply(names_features, pvalue_LRTest);
names(pvalues) <- names_features;
pvalues[order(pvalues, decreasing=FALSE)];
```

```{r}
#Essai pour contrecarrer l'erreur (une des colonnes a une valeur constante, fait bugger, ne calculer que sur les colonnes dont la valeur est non constante)
names_features <- colnames(Dfprediction);
names_features <- names_features[names_features != 'diagnosis'];
values_count <- sapply(lapply(names_features, unique), length)
pvalues <- sapply(names_features >1 , pvalue_LRTest);
names(pvalues) <- names_features;
pvalues[order(pvalues, decreasing=FALSE)];
```

# III) Predict the result for our test dataset and assess the error of prediction

```{r}
print(Dfprediction.test)
```
```{r}
# Predicting on test data based on training set
Dfprediction.glm.predict <- predict(Dfprediction.glm,Dfprediction.test, type = "response")
#predict is a generic function for predictions from the results of various model fitting functions
summary(Dfprediction.glm.predict)
```
We can see in the cell above that on average patient have a probability 0.5477 to have PDAC cancer.



```{r}
print(Dfprediction.glm.predict)
```
```{r}
tapply(Dfprediction.glm.predict, Dfprediction.test$diagnosis, mean)
#compute the mean to get 0 and to get 1
```
A confusion matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier. 
```{r}
# Confusion matrix for threshold of p
p = 0.5
#table() returns a contingency table
dfPrediction.confusion = table(Dfprediction.test$diagnosis, Dfprediction.glm.predict > p)

rownames(dfPrediction.confusion) <- c("Truely NOT DETECTED","Truely DETECTED");
if (length(colnames(dfPrediction.confusion)) == 2){
  colnames(dfPrediction.confusion) <- c("Predict NOT DETECTED","Predict DETECTED")
} else {
  if (colnames(dfPrediction.confusion)[1] == 'TRUE'){
    colnames(dfPrediction.confusion) <- c("Predict DETECTED")}
}
print(dfPrediction.confusion)
```
```{r}
# False negative error rate (Type II error)
dfPrediction.type2error = Dfprediction.confusion[1,1]/ (Dfprediction.confusion[1,1]+Dfprediction.confusion[2,2])
print(paste("The proportion of errors of Type II is ",as.character(dfPrediction.type2error)));
```

